SENTIMENT ANALYSIS
here we are training our model i.e positive and negative sentences/comments in our tensorflow neural network model with the help of NLTK(natural language processing). hence, now our model can be able to specify weather the comment was positive or negative 


import tensorflow as tf
from nltk.tokenize import word_tokenize
import numpy as np
import random
from collections import Counter
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()

def create_lexicon(pos,neg):

	lexicon = []
	with open(pos,'r') as f:
		contents = f.readlines()
		for l in contents:
			all_words = word_tokenize(l.lower())
			lexicon += list(all_words)

	with open(neg,'r') as f:
		contents = f.readlines()
		for l in contents:
			all_words = word_tokenize(l.lower())
			lexicon += list(all_words)

	lexicon = [lemmatizer.lemmatize(i) for i in lexicon]
	w_counts = Counter(lexicon)
	l2 = []
	for w in w_counts:

		if 1000 > w_counts[w] > 50:
			l2.append(w)
	#print(len(l2))
	return l2

def sample_handling(sample,lexicon,classification):
	featureset = []
	with open(sample,'r') as f:
		contents = f.readlines()

		for l in contents:
			all_words = word_tokenize(l.lower())
			current_words = [lemmatizer.lemmatize(i) for i in all_words]
			features = np.zeros(len(lexicon))
			for word in current_words:
				if word.lower() in lexicon:
					index_value = lexicon.index(word.lower())
					features[index_value]=features[index_value]+1

			features = list(features)
			featureset.append([features, classification])

	return featureset

def create_feature_sets_and_labels(pos,neg,test_size = 0.1):
	lexicon = create_lexicon(pos,neg)
	features = []
	features += sample_handling('pos.txt',lexicon,[1,0])
	features += sample_handling('neg.txt',lexicon,[0,1])
	random.shuffle(features)
	features = np.array(features)

	testing_size = int(test_size*len(features))

	train_x = list(features[:,0][:-testing_size])
	train_y = list(features[:,1][:-testing_size])
	test_x = list(features[:,0][-testing_size:])
	test_y = list(features[:,1][-testing_size:])

	return train_x,train_y,test_x,test_y,lexicon


train_x,train_y,test_x,test_y,lexicon = create_feature_sets_and_labels('pos.txt','neg.txt')

print('part-1 done!!')

##########   NEURAL PART STARTED ######################
""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
"""
input_layer*W1 +b1 =layer1 >> activation(layer1) >> activation(layer1) *w2+b2 = layer2
>>acti(layer2)>> output-layer

## comparing output-layer with output
cost entropy(output-layer,output)
then optimizer i.e. minimizing our cost entropy with ##backpropogation
"""

input_nodes = len(train_x)
no_class = len(train_y)
n_nodes1 = 1000
n_nodes2 = 500
n_nodes3 = 250
n_nodes = 125
batch_size = 100
 ##class = 10 , bcoz we are pridicting 10 classes i.e from 0-9

## x = [none = to flat array , 28 * 28 ]
## x = height * width , height = none.
x =tf.placeholder("float",[None,len(lexicon)])
y =tf.placeholder("float")

## 1 input layer -- 3 hidden layer -- 1 outputlayer

## creating hidden layer framework
## hidden-layer-1 = ['weights','basis'] where weights=matrix of [data,nodes] and bias = [nodes]


def neural_net_model(x):
    hidden_layer_1 = {"weights":tf.Variable(tf.random_normal([input_nodes,n_nodes1])),
                      "basis":tf.Variable(tf.random_normal([n_nodes1]))}

    hidden_layer_2 = {"weights": tf.Variable(tf.random_normal([n_nodes1, n_nodes2])),
                      "basis": tf.Variable(tf.random_normal([n_nodes2]))}

    hidden_layer_3 = {"weights": tf.Variable(tf.random_normal([n_nodes2, n_nodes3])),
                      "basis": tf.Variable(tf.random_normal([n_nodes3]))}

    output_layer = {"weights": tf.Variable(tf.random_normal([n_nodes3, no_class])),
                      "basis": tf.Variable(tf.random_normal([no_class]))}


##  layer1 = data*weights + bias  ||   [1*data]*[data*nodes]+[1*bias] = layer1
##  then activation of layer1(i.e neuron burn up or not)
## ouput-layer dosnt have activation layer


    layer_1 = tf.add(tf.matmul(x,hidden_layer_1['weights']), hidden_layer_1['basis'])
    layer_1 = tf.nn.relu(layer_1)

    layer_2 = tf.add(tf.matmul(layer_1, hidden_layer_2['weights']), hidden_layer_2['basis'])
    layer_2 = tf.nn.relu(layer_2)

    layer_3 = tf.add(tf.matmul(layer_2, hidden_layer_3['weights']), hidden_layer_3['basis'])
    layer_3 = tf.nn.relu(layer_3)

    o_layer = tf.add(tf.matmul(layer_3, output_layer['weights']), output_layer['basis'])


    return o_layer

## hidden layer framework is completed
##....................................................................................................##




def train_neural_netwrok(x):
##data is passed through neurals and output is get in prediction
    prediction = neural_net_model(x)
##comparing our NEURAL-OUTPUT with (y) in cost function
	##mean is calculated of every data point
	cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))
	optimizer = tf.train.AdamOptimizer().minimize(cost_function)
    epoch_no = 4
    with tf.Session() as sess:
    # OLD:
    # sess.run(tf.initialize_all_variables())
    # NEW:
        sess.run(tf.initialize_all_variables())
        for epoch in range(epoch_no):
            epoch_loss = 0
            i = 0
            while i < len(train_x):
                start = i
                end = i + batch_size
                batch_x = np.array(train_x[start:end])
                batch_y = np.array(train_y[start:end])

                batch, c = sess.run([optimizer, cost_function], feed_dict={x: batch_x,
                                                              y: batch_y})
            # print('batch', (end/batch_size),'completed')

                i += batch_size

        print('Epoch', epoch, 'completed out of', epoch_no, 'loss:', epoch_loss)

    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))

    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))
    print('Accuracy:', accuracy.eval({x: test_x, y: test_y}))

train_neural_network(x)















